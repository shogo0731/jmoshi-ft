{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb76be09-a929-4e09-947b-5f656541f094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install librosa soundfile\n",
    "# #mecabと日本語辞書をインストール\n",
    "# !pip install mecab-python3 \\\n",
    "#  unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d185bc-1fe0-4ead-95de-0ef4b34a321d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !conda install -y -c conda-forge kaldi kalpy pynini\n",
    "\n",
    "# !pip install montreal-forced-aligner \\\n",
    "# spacy \\\n",
    "# sudachipy \\\n",
    "# sudachidict-core \\\n",
    "# pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc7d51f-1d66-4e58-90bc-5d37bb3ff55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93cc73ba-ab99-42a1-aa61-407b4f424c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local version of model already exists (/users/s1f102201582/Documents/MFA/pretrained_models/dictionary/japanese_mfa.dict). Use the --ignore_cache flag to force redownloading.\n",
      "Local version of model already exists (/users/s1f102201582/Documents/MFA/pretrained_models/acoustic/japanese_mfa.zip). Use the --ignore_cache flag to force redownloading.\n"
     ]
    }
   ],
   "source": [
    "# # 日本語辞書のダウンロード\n",
    "!mfa model download dictionary japanese_mfa\n",
    "\n",
    "# 日本語音響モデルのダウンロード\n",
    "!mfa model download acoustic japanese_mfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10c0d2c-9e6a-499b-9837-aa4ef3a77ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import soundfile as sf\n",
    "\n",
    "# wav, sr = librosa.load(\"test.wav\")\n",
    "# sf.write(\"./test/test.wav\", wav, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad7e925-fbc8-4d4e-b57e-552fba126acf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def lst_to_txt(lst):\n",
    "    result = \"\"\n",
    "    for i in range(len(lst)):\n",
    "        if i % 2 == 0:\n",
    "            result += f\"Speaker 1: {lst[i]}\\n\"\n",
    "        else:\n",
    "            result += f\"Speaker 2: {lst[i]}\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de1dfee7-37a5-4ecb-a931-88212b5fa088",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import MeCab\n",
    "# import re\n",
    "\n",
    "# # 句読点のパターン\n",
    "# PUNCT_RE = re.compile(r'^[。、,.!?！？…]+$')\n",
    "\n",
    "# def tokenize_text(text):\n",
    "#     tokens = []\n",
    "#     try:\n",
    "#         # MeCabのタガーを初期化\n",
    "#         tagger = MeCab.Tagger()\n",
    "\n",
    "#         # MeCabは内部でShift-JISやEUC-JPを期待することがあるため、\n",
    "#         # UnicodeDecodeErrorを避けるために明示的にUTF-8でエンコード・デコードする\n",
    "#         # parseToNodeは、より詳細な情報をノードオブジェクトとして取得できるメソッド\n",
    "#         node = tagger.parseToNode(text)\n",
    "#         while node:\n",
    "#             if not node.surface:\n",
    "#                 pass\n",
    "                \n",
    "#             elif PUNCT_RE.match(node.surface) and tokens:\n",
    "#                 # 句読点なら直前トークンに連結\n",
    "#                 tokens[-1] += node.surface\n",
    "#             else:\n",
    "#                 # 通常トークンはそのまま追加\n",
    "#                 tokens.append(node.surface)\n",
    "#             node = node.next\n",
    "#     except RuntimeError as e:\n",
    "#         print(f\"MeCabの実行中にエラーが発生しました: {e}\", file=sys.stderr)\n",
    "        \n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33f761f-8d9c-47d4-bc1e-aa95bfb5c1ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_txt_file(input_txt):\n",
    "    with open(\"./test/test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(input_txt)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6522ec9c-a2bd-4f23-a4e5-44ae26f64153",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_txt_file_using_mecab(input_txt):\n",
    "    tokens = tokenize_text(input_txt)\n",
    "    output = \"\"\n",
    "    for token in tokens:\n",
    "        output += token + \"\\n\"\n",
    "        \n",
    "    with open(\"./test/test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96aa93a5-a02e-4d3e-9c21-69c43aa08261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_txt = \"\"\n",
    "# for txt in txts:\n",
    "#     input_txt += txt\n",
    "\n",
    "# generate_txt_file_using_mecab(input_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07ef028-537f-4fe0-9ec7-3317e6c53b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Setting up corpus information\u001b[33m...\u001b[0m                                      \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Loading corpus from source files\u001b[33m...\u001b[0m                                   \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Found \u001b[1;36m1\u001b[0m speaker across \u001b[1;36m1\u001b[0m file, average number of utterances per       \n",
      "\u001b[2;36m \u001b[0m         speaker: \u001b[1;36m1.0\u001b[0m                                                          \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Initializing multiprocessing jobs\u001b[33m...\u001b[0m                                  \n",
      "\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Number of jobs was specified as \u001b[1;36m3\u001b[0m, but due to only having \u001b[1;36m1\u001b[0m speakers, \n",
      "\u001b[2;36m \u001b[0m         MFA will only use \u001b[1;36m1\u001b[0m jobs. Use the --single_speaker flag if you would  \n",
      "\u001b[2;36m \u001b[0m         like to split utterances across jobs regardless of their speaker.     \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Normalizing text\u001b[33m...\u001b[0m                                                   \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating MFCCs\u001b[33m...\u001b[0m                                                   \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Calculating CMVN\u001b[33m...\u001b[0m                                                   \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating final features\u001b[33m...\u001b[0m                                          \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Creating corpus split\u001b[33m...\u001b[0m                                              \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Compiling training graphs\u001b[33m...\u001b[0m                                          \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Performing first-pass alignment\u001b[33m...\u001b[0m                                    \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating alignments\u001b[33m...\u001b[0m                                              \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Collecting phone and word alignments from alignment lattices\u001b[33m...\u001b[0m       \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Analyzing alignment quality\u001b[33m...\u001b[0m                                        \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Exporting alignment TextGrids to mfa_test_out\u001b[33m...\u001b[0m                      \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Finished exporting TextGrids to mfa_test_out!                         \n",
      "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Done! Everything took \u001b[1;36m138.664\u001b[0m seconds                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.4 ms, sys: 11.9 ms, total: 58.2 ms\n",
      "Wall time: 2min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['mfa', 'align', './mfa_test_in/', 'japanese_mfa', '/users/s1f102201582/Documents/MFA/pretrained_models/acoustic/japanese_mfa.zip', './mfa_test_out/', '--quiet', '--fine_tune', '--overwrite', '--clean', '--final_clean', '--output_format', 'json', '--beam', '1000', '--retry_beam', '4000', '--config_path', 'mfa_config.yaml'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import subprocess\n",
    "from os.path import expanduser, join\n",
    "\n",
    "home_dir = expanduser(\"~\")\n",
    "model_dir = join(home_dir, \"Documents/MFA/pretrained_models/acoustic/japanese_mfa.zip\")\n",
    "\n",
    "subprocess.run([\n",
    "    \"mfa\",\n",
    "    \"align\",\n",
    "    \"./mfa_test_in/\",\n",
    "    \"japanese_mfa\",\n",
    "    model_dir,\n",
    "    \"./mfa_test_out/\",\n",
    "    \"--quiet\",\n",
    "    \"--fine_tune\", \n",
    "    \"--overwrite\",\n",
    "    \"--clean\",\n",
    "    \"--final_clean\",\n",
    "    \"--output_format\", \"json\",\n",
    "    \"--beam\", \"1000\",\n",
    "    \"--retry_beam\", \"4000\",\n",
    "    \"--config_path\", \"mfa_config.yaml\",\n",
    "])\n",
    "\n",
    "    # \"--punctuation\", '\"…\"',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13d5f1a2-6eee-40e1-b07a-46ba30ce6a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !mfa validate --ignore_acoustics ./test/ japanese_mfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f7075-c4bc-4e6a-8951-6203e7a3df23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
